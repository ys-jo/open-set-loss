{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1654578949870,
     "user": {
      "displayName": "조영섭",
      "userId": "14647193603394919754"
     },
     "user_tz": -540
    },
    "id": "dvhQsK-pDR8t",
    "outputId": "446bd01b-f082-4791-9e87-9e5db450d056"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processor\t: 0\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 63\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2299.998\n",
      "cache size\t: 46080 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 0\n",
      "initial apicid\t: 0\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
      "bogomips\t: 4599.99\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 1\n",
      "vendor_id\t: GenuineIntel\n",
      "cpu family\t: 6\n",
      "model\t\t: 63\n",
      "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
      "stepping\t: 0\n",
      "microcode\t: 0x1\n",
      "cpu MHz\t\t: 2299.998\n",
      "cache size\t: 46080 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 1\n",
      "initial apicid\t: 1\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
      "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n",
      "bogomips\t: 4599.99\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 46 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "Tue Jun  7 05:15:50 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   41C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! cat /proc/cpuinfo\n",
    "\n",
    "!nvidia-smi\n",
    "# !pkill -3 python3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 9896,
     "status": "ok",
     "timestamp": 1654579474741,
     "user": {
      "displayName": "조영섭",
      "userId": "14647193603394919754"
     },
     "user_tz": -540
    },
    "id": "UkhtjpCfcs3X"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import shutil\n",
    "#file_name = \"/content/drive/MyDrive/dataset.zip\"\n",
    "#with ZipFile(file_name,'r') as zip:\n",
    "#    zip.extractall()\n",
    "#shutil.rmtree(\"/content/MNIST_JPG_Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1654579523036,
     "user": {
      "displayName": "조영섭",
      "userId": "14647193603394919754"
     },
     "user_tz": -540
    },
    "id": "Ou14DctIiYmg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_set_path, transforms=None):\n",
    "        self.data_set_path = data_set_path\n",
    "        self.image_files_path, self.labels, self.length, self.num_classes = self.read_data_set()\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def read_data_set(self):\n",
    "\n",
    "        all_img_files = []\n",
    "        all_labels = []\n",
    "\n",
    "        class_names = os.walk(self.data_set_path).__next__()[1]\n",
    "        class_names.sort()\n",
    "        if \"background\" in class_names:\n",
    "            class_names.remove(\"background\")\n",
    "            class_names.append(\"background\")\n",
    "        print(class_names)\n",
    "\n",
    "        for index, class_name in enumerate(class_names):\n",
    "            label = index\n",
    "            img_dir = os.path.join(self.data_set_path, class_name)\n",
    "            img_files = os.walk(img_dir).__next__()[2]\n",
    "\n",
    "            for img_file in img_files:\n",
    "                img_file = os.path.join(img_dir, img_file)\n",
    "                img = Image.open(img_file)\n",
    "                if img is not None:\n",
    "                    all_img_files.append(img_file)\n",
    "                    all_labels.append(label)\n",
    "\n",
    "        return all_img_files, all_labels, len(all_img_files), len(class_names)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_files_path[index])\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4516,
     "status": "ok",
     "timestamp": 1654579603077,
     "user": {
      "displayName": "조영섭",
      "userId": "14647193603394919754"
     },
     "user_tz": -540
    },
    "id": "a5lBN13c5iHU",
    "outputId": "db6da736-2749-4c8b-c8c8-c5b0be501c93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'background']\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'background']\n",
      "number of training data :  26008\n",
      "number of test data :  3058\n"
     ]
    }
   ],
   "source": [
    "#use cuda\n",
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if is_cuda else 'cpu')\n",
    "\n",
    "\n",
    "#transforms\n",
    "class make_background_class():\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        background class number\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, class_num):\n",
    "        self.class_num = int(class_num)\n",
    "\n",
    "    def __call__(self, img, target):\n",
    "        print(img)\n",
    "        print(target)\n",
    "        return img, self.class_num\n",
    "\n",
    "#dataset\n",
    "\"\"\"\n",
    "dataset structure\n",
    "train/\n",
    "    class1/\n",
    "        *.jpg\n",
    "    class2/\n",
    "        *.jpg\n",
    "    class3/\n",
    "        *.jpg\n",
    "    background/\n",
    "        *.jpg\n",
    "test/\n",
    "    class1/\n",
    "        *.jpg\n",
    "    class2/\n",
    "        *.jpg\n",
    "    class3/\n",
    "        *.jpg\n",
    "    background/\n",
    "        *.jpg\n",
    "\"\"\"\n",
    "\n",
    "mean=[0.486,0.456,0.406]\n",
    "std=[0.229,0.224,0.225]\n",
    "t = [transforms.Resize((160, 160)),\n",
    "     # transforms.Grayscale(1),\n",
    "     transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)]\n",
    "t = transforms.Compose(t)\n",
    "train_dataset = CustomDataset(data_set_path=\"./KWS_7class_aug/train\", transforms=t)\n",
    "test_dataset = CustomDataset(data_set_path=\"./KWS_7class_aug/test\", transforms=t)\n",
    "class_names = os.walk(\"./KWS_7class_aug/train\").__next__()[1]\n",
    "class_names.sort()\n",
    "if \"background\" in class_names:\n",
    "    class_names.remove(\"background\")\n",
    "    class_names.append(\"background\")\n",
    "\n",
    "\n",
    "print('number of training data : ',len(train_dataset))\n",
    "print('number of test data : ',len(test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1654581035953,
     "user": {
      "displayName": "조영섭",
      "userId": "14647193603394919754"
     },
     "user_tz": -540
    },
    "id": "bmuO0k_w6wTF",
    "outputId": "6fc2109c-c056-4faf-d8ff-e6a999842817"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 파라미터 설정\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "epoch_num = 30\n",
    "\n",
    "# data 확인\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "image, label = train_dataset[1]\n",
    "plt.imshow(image.squeeze().numpy().T)\n",
    "plt.title('label : %s' % label)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1654581038331,
     "user": {
      "displayName": "조영섭",
      "userId": "14647193603394919754"
     },
     "user_tz": -540
    },
    "id": "6yZg4RIL7Z7w"
   },
   "outputs": [],
   "source": [
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size = batch_size, drop_last=True, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size = batch_size, drop_last=True, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1654584610560,
     "user": {
      "displayName": "조영섭",
      "userId": "14647193603394919754"
     },
     "user_tz": -540
    },
    "id": "QIpk5Uy8lhBr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Entropic Open-set loss\n",
    "class Entropic_Open_set_Loss():\n",
    "    def __init__(self, class_names):\n",
    "        self.class_num = len(class_names)\n",
    "        self.batch_size = batch_size\n",
    "        self.Cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "    def __call__(self, output, target_batch):\n",
    "        loss = 0\n",
    "        for i, target in enumerate(target_batch):\n",
    "            if target == self.class_num - 1:\n",
    "                # background class\n",
    "                div = 1/self.class_num\n",
    "                for index in range(self.class_num - 1):\n",
    "                    loss -= torch.log(output[i][index])*div\n",
    "            else:\n",
    "                # CELoss\n",
    "                loss -= torch.log(output[i][target])\n",
    "                # print(loss)\n",
    "\n",
    "        loss_mean = loss/len(target_batch)\n",
    "        return loss_mean\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 509,
     "status": "ok",
     "timestamp": 1654584612810,
     "user": {
      "displayName": "조영섭",
      "userId": "14647193603394919754"
     },
     "user_tz": -540
    },
    "id": "u_DpFx_s7oBL"
   },
   "outputs": [],
   "source": [
    "# 모델\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from typing import Callable, Any, Optional, List\n",
    "torch.backends.cudnn.enabled = True\n",
    "__all__ = ['MobileNetV2', 'mobilenet_v2']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'mobilenet_v2': 'https://download.pytorch.org/models/mobilenet_v2-b0353104.pth',\n",
    "}\n",
    "\n",
    "\n",
    "  \n",
    "try:\n",
    "    from torch.hub import load_state_dict_from_url\n",
    "except ImportError:\n",
    "    from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "\n",
    "def _make_divisible(v: float, divisor: int, min_value: Optional[int] = None) -> int:\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "class ConvBNActivation(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_planes: int,\n",
    "        out_planes: int,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 1,\n",
    "        groups: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        activation_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        dilation: int = 1,\n",
    "    ) -> None:\n",
    "        padding = (kernel_size - 1) // 2 * dilation\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if activation_layer is None:\n",
    "            activation_layer = nn.ReLU6\n",
    "        super(ConvBNReLU, self).__init__(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, dilation=dilation, groups=groups,\n",
    "                      bias=False),\n",
    "            norm_layer(out_planes),\n",
    "            activation_layer(inplace=True)\n",
    "        )\n",
    "        self.out_channels = out_planes\n",
    "\n",
    "\n",
    "# necessary for backwards compatibility\n",
    "ConvBNReLU = ConvBNActivation\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inp: int,\n",
    "        oup: int,\n",
    "        stride: int,\n",
    "        expand_ratio: int,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        hidden_dim = int(round(inp * expand_ratio))\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "        if expand_ratio != 1:\n",
    "            # pw\n",
    "            layers.append(ConvBNReLU(inp, hidden_dim, kernel_size=1, norm_layer=norm_layer))\n",
    "        layers.extend([\n",
    "            # dw\n",
    "            ConvBNReLU(hidden_dim, hidden_dim, stride=stride, groups=hidden_dim, norm_layer=norm_layer),\n",
    "            # pw-linear\n",
    "            nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "            norm_layer(oup),\n",
    "        ])\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        self.out_channels = oup\n",
    "        self._is_cn = stride > 1\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    name = 'mobilenetv2'\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 1000,\n",
    "        width_mult: float = 1.0,\n",
    "        custom_class_num: int = 7,\n",
    "        inverted_residual_setting: Optional[List[List[int]]] = None,\n",
    "        round_nearest: int = 8,\n",
    "        block: Optional[Callable[..., nn.Module]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        MobileNet V2 main class\n",
    "        Args:\n",
    "            num_classes (int): Number of classes\n",
    "            width_mult (float): Width multiplier - adjusts number of channels in each layer by this amount\n",
    "            inverted_residual_setting: Network structure\n",
    "            round_nearest (int): Round the number of channels in each layer to be a multiple of this number\n",
    "            Set to 1 to turn off rounding\n",
    "            block: Module specifying inverted residual building block for mobilenet\n",
    "            norm_layer: Module specifying the normalization layer to use\n",
    "        \"\"\"\n",
    "        super(MobileNetV2, self).__init__()\n",
    "\n",
    "        if block is None:\n",
    "            block = InvertedResidual\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "\n",
    "        if inverted_residual_setting is None:\n",
    "            inverted_residual_setting = [\n",
    "                # t, c, n, s\n",
    "                [1, 16, 1, 1],\n",
    "                [6, 24, 2, 2],\n",
    "                [6, 32, 3, 2],\n",
    "                [6, 64, 4, 2],\n",
    "                [6, 96, 3, 1],\n",
    "                [6, 160, 3, 2],\n",
    "                [6, 320, 1, 1],\n",
    "            ]\n",
    "\n",
    "        # only check the first element, assuming user knows t,c,n,s are required\n",
    "        if len(inverted_residual_setting) == 0 or len(inverted_residual_setting[0]) != 4:\n",
    "            raise ValueError(\"inverted_residual_setting should be non-empty \"\n",
    "                             \"or a 4-element list, got {}\".format(inverted_residual_setting))\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = _make_divisible(input_channel * width_mult, round_nearest)\n",
    "        self.last_channel = _make_divisible(last_channel * max(1.0, width_mult), round_nearest)\n",
    "        features: List[nn.Module] = [ConvBNReLU(3, input_channel, stride=2, norm_layer=norm_layer)]\n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in inverted_residual_setting:\n",
    "            output_channel = _make_divisible(c * width_mult, round_nearest)\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else 1\n",
    "                features.append(block(input_channel, output_channel, stride, expand_ratio=t, norm_layer=norm_layer))\n",
    "                input_channel = output_channel\n",
    "        # building last several layers\n",
    "        features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1, norm_layer=norm_layer))\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*features)\n",
    "\n",
    "        # building classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.last_channel, num_classes),\n",
    "            nn.Linear(num_classes, custom_class_num)\n",
    "        )\n",
    "\n",
    "        # weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # This exists since TorchScript doesn't support inheritance, so the superclass method\n",
    "        # (this one) needs to have a name other than `forward` that can be accessed in a subclass\n",
    "        x = self.features(x)\n",
    "        # Cannot use \"squeeze\" as batch-size can be 1\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        output = F.softmax(x, dim=1)\n",
    " \n",
    "        return output\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "    #def get_input_size(self):\n",
    "    #   return 224, 224\n",
    "\n",
    "\n",
    "def mobilenet_v2(pretrained: bool = True, progress: bool = True, **kwargs: Any) -> MobileNetV2:\n",
    "    \"\"\"\n",
    "    Constructs a MobileNetV2 architecture from\n",
    "    `\"MobileNetV2: Inverted Residuals and Linear Bottlenecks\" <https://arxiv.org/abs/1801.04381>`_.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = MobileNetV2(**kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls['mobilenet_v2'],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict,strict=False)\n",
    "    return model\n",
    "\n",
    "model = mobilenet_v2(custom_class_num = len(class_names) - 1)      \n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#open set loss\n",
    "criterion = Entropic_Open_set_Loss(class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 471652,
     "status": "ok",
     "timestamp": 1654585086365,
     "user": {
      "displayName": "조영섭",
      "userId": "14647193603394919754"
     },
     "user_tz": -540
    },
    "id": "0KLCM-QV72nH",
    "outputId": "fece73b1-d25f-4cae-de1c-9ddad204fc3c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e794028eb7dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "model.train()\n",
    "i = 1\n",
    "for epoch in range(epoch_num):\n",
    "    for data, target in train_loader:\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        # print(\"aaa\",loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Train Step : {}\\tLoss : {:3f}\".format(i, loss.item()))\n",
    "            \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "executionInfo": {
     "elapsed": 1182,
     "status": "error",
     "timestamp": 1654586605884,
     "user": {
      "displayName": "조영섭",
      "userId": "14647193603394919754"
     },
     "user_tz": -540
    },
    "id": "C8jSIbkk75WT",
    "outputId": "fe71fed9-9cc7-4e59-aa4e-54121b153e1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n",
      "No\n",
      "No\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 10.76 GiB total capacity; 9.50 GiB already allocated; 7.06 MiB free; 9.63 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-c28ea140480a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/viewer/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-38c1a05be93b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;31m#def get_input_size(self):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-38c1a05be93b>\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# This exists since TorchScript doesn't support inheritance, so the superclass method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# (this one) needs to have a name other than `forward` that can be accessed in a subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;31m# Cannot use \"squeeze\" as batch-size can be 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/viewer/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/viewer/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/viewer/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-38c1a05be93b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/viewer/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/viewer/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/viewer/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/viewer/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/viewer/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/viewer/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/viewer/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    395\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 396\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 10.76 GiB total capacity; 9.50 GiB already allocated; 7.06 MiB free; 9.63 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "#모델 평가\n",
    "model.eval()    # 평가시에는 dropout이 OFF 된다.\n",
    "correct = 0\n",
    "no = 0\n",
    "c = 0\n",
    "for data, target in test_loader:\n",
    "    if torch.cuda.is_available():\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "    output = model(data)\n",
    "    # print(output)\n",
    "    prediction = torch.max(output[0])\n",
    "    # print(prediction)\n",
    "    # print(\"target\", target)\n",
    "    for i in range(batch_size):\n",
    "        # print(output[i])\n",
    "        # print(target[i])\n",
    "        if torch.max(output[i]) < 0.5 and target[i] == 7:\n",
    "            c += torch.max(output[i])\n",
    "            correct += 1\n",
    "            no +=1\n",
    "        elif torch.max(output[i]) < 0.5 and target[i] != 10:\n",
    "            print(\"No\")\n",
    "            # no += 1\n",
    "        else:\n",
    "            correct += torch.argmax(output[i]).eq(target[i])\n",
    "print(\"C\", c/no)\n",
    "print(\"No\",no)\n",
    "print('Test set Accuracy : {:.2f}%'.format(100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun  8 07:46:38 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:19:00.0 Off |                  N/A |\r\n",
      "| 40%   38C    P8    12W / 250W |     10MiB / 11264MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA GeForce ...  Off  | 00000000:1A:00.0 Off |                  N/A |\r\n",
      "| 41%   41C    P8     6W / 250W |     10MiB / 11264MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:68:00.0  On |                  N/A |\r\n",
      "| 41%   41C    P8     8W / 250W |    358MiB / 11264MiB |      2%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1390      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    0   N/A  N/A      2533      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    1   N/A  N/A      1390      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    1   N/A  N/A      2533      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "|    2   N/A  N/A      1390      G   /usr/lib/xorg/Xorg                102MiB |\r\n",
      "|    2   N/A  N/A      2533      G   /usr/lib/xorg/Xorg                229MiB |\r\n",
      "|    2   N/A  N/A      2652      G   /usr/bin/gnome-shell               13MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1654578950829,
     "user": {
      "displayName": "조영섭",
      "userId": "14647193603394919754"
     },
     "user_tz": -540
    },
    "id": "H94Sr8AGCF3d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c4d69c0095a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataprep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mletters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Vanilla_{}.{}'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneg_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Not_MNIST'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmnist_intermediate_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_tools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mneg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mneg_intermediate_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_tools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mnist' is not defined"
     ]
    }
   ],
   "source": [
    "import dataprep\n",
    "def analyze(model,pos_x=mnist.X_test,pos_y=mnist.labels_test,neg=letters.X_test,file_name='Vanilla_{}.{}',neg_labels='Not_MNIST'):\n",
    "    mnist_intermediate_output=model_tools.extract_features(model,pos_x,layer_name=['fc','softmax','pred'])\n",
    "    if neg is not None:\n",
    "        neg_intermediate_output=model_tools.extract_features(model,neg,layer_name=['fc','softmax','pred'])\n",
    "    pred_weights=model.get_layer('pred').get_weights()[0]\n",
    "    \n",
    "    visualizing_tools.plotter_2D(\n",
    "                                    mnist_intermediate_output[0],\n",
    "                                    pos_y,\n",
    "                                    neg_intermediate_output[0],\n",
    "                                    final=True,\n",
    "                                    file_name='LeNet++/Final_Plots/'+file_name,\n",
    "                                    pos_labels='MNIST Digits',\n",
    "                                    neg_labels=neg_labels,\n",
    "                                    pred_weights=pred_weights\n",
    "                                )\n",
    "    \n",
    "    visualizing_tools.plot_softmax_histogram(\n",
    "                                                mnist_intermediate_output[1],\n",
    "                                                neg_intermediate_output[1],\n",
    "                                                file_name='LeNet++/Final_Plots/'+file_name,\n",
    "                                                pos_labels='MNIST Digits',\n",
    "                                                neg_labels=neg_labels\n",
    "                                            )\n",
    "    gt_y = np.concatenate((mnist.labels_test,np.ones(neg_intermediate_output[1].shape[0])*10),axis=0)\n",
    "    pred_y = np.concatenate((mnist_intermediate_output[1],neg_intermediate_output[1]),axis=0)\n",
    "    evaluation_tools.write_file_for_DIR(gt_y,\n",
    "                                        pred_y,\n",
    "                                        file_name=('LeNet++/DIRs/'+file_name).format(neg_labels,'txt'),\n",
    "                                        num_of_known_classes=10\n",
    "                                       )\n",
    "    evaluation_tools.write_file_for_DIR(gt_y,\n",
    "                                        pred_y,\n",
    "                                        file_name=('LeNet++/DIRs/'+file_name).format(neg_labels,'txt'),\n",
    "                                        feature_vector=np.concatenate((mnist_intermediate_output[0],neg_intermediate_output[0])),\n",
    "                                        num_of_known_classes=10\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPqteBFItARJ1e1TBk3rnCM",
   "collapsed_sections": [],
   "mount_file_id": "1ItchOK0W_J7fbUcPHzHZ5pDUX6ALZlcj",
   "name": "open-set-classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
